##ëª¨ë¸ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

import streamlit as st
import ollama
import re  # â† ì¶”ê°€

st.set_page_config(page_title="ë‹¤ìŒ ë©˜íŠ¸ ì¶”ì²œ (Ollama)", page_icon="ğŸ’¬")
st.title("ğŸ’¬ ë‹¤ìŒ ë©˜íŠ¸ ì¶”ì²œ (Ollama)")

# qwen3_cpu:latest                                           
# qwen3:8b                                                    
# smooth:latest                                               
# EEVE-Korean-10.8B:latest                                   
# hf.co/heegyu/EEVE-Korean-Instruct-10.8B-v1.0-GGUF:Q4_K_M    
# llama3.1:8b                                               
# gemma3:4b ----

with st.sidebar:
    st.markdown("### ì„¤ì •")
    MODEL = st.text_input("ëª¨ë¸ëª…", value="EEVE-Korean-10.8B:latest")  # ëŒ€í™”í˜•ì€ ë³´í†µ :instruct ê¶Œì¥
    N = st.slider("ì œì•ˆ ê°œìˆ˜", 3, 5, 3, 1)
    TEMP = st.slider("temperature", 0.0, 1.5, 0.7, 0.1)
    if st.button("ì„¸ì…˜ ì´ˆê¸°í™”"):
        st.session_state.clear()
        st.rerun()

system_message = f"""
ë„ˆëŠ” 'ëŒ€í™” ì´ì–´ì£¼ê¸° ì½”ì¹˜'ì•¼. í•­ìƒ í•œêµ­ì–´ ë°˜ë§ë¡œ ì§§ê³  ìì—°ìŠ¤ëŸ½ê²Œ ì œì•ˆí•´.
ì¶œë ¥ ê·œì¹™:
- ë”± {N}ê°œ ì œì•ˆë§Œ.
- ê° ì œì•ˆì€ 1ë¬¸ì¥, 30ì ë‚´ì™¸.
"""

if "turns" not in st.session_state:
    st.session_state.turns = []

def ensure_model_exists(name: str) -> bool:
    try:
        ollama.show(model=name)
        return True
    except Exception:
        st.error(f"âŒ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: `{name}`\n- `ollama list`ë¡œ í™•ì¸\n- í•„ìš” ì‹œ `ollama pull {name}`")
        return False
    
import re

def clean_model_output(text: str) -> str:
    """
    ëª¨ë¸ì´ reasoning(ìƒê°)ì´ë‚˜ ì§„ë‹¨ìš© íƒœê·¸ë¥¼ ë…¸ì¶œí•  ë•Œë¥¼ ëŒ€ë¹„í•´ ì•ˆì „í•˜ê²Œ ì œê±°í•œë‹¤.
    - <think> ... </think>
    - /think, /no_think (ë‹¨ë… ë¼ì¸ or ë¬¸ì¥ ì¤‘ í¬í•¨)
    - <tool_call> ... </tool_call> (í˜¹ì‹œ í…œí”Œë¦¿ì— ìˆì„ ë•Œ)
    - ë¶ˆí•„ìš”í•œ ë§ˆì»¤ ì—¬ë°± ì •ë¦¬
    """
    if not text:
        return text

    # 1) <think> ë¸”ë¡ ì œê±° (ê°œí–‰ í¬í•¨, ëŒ€/ì†Œë¬¸ì ë¬´ì‹œ)
    text = re.sub(r'(?is)<\s*think\s*>.*?<\s*/\s*think\s*>', '', text)

    # 2) /think, /no_think í† í° ì œê±° (ë¼ì¸ ë‹¨ë…/ë¬¸ì¥ ë‚´ ë‘˜ ë‹¤ ì»¤ë²„)
    text = re.sub(r'(?im)^\s*/\s*(?:no_)?think\s*$', '', text)  # ë‹¨ë… ë¼ì¸
    text = re.sub(r'/\s*(?:no_)?think\b', '', text)             # ë¬¸ì¥ ì¤‘ í¬í•¨

    # 3) (ì˜µì…˜) tool_call ë¸”ë¡ ì œê±°
    text = re.sub(r'(?is)<\s*tool_call\s*>.*?<\s*/\s*tool_call\s*>', '', text)

    # 4) ë‚¨ì€ íƒœê·¸/ë§ˆì»¤ ì—¬ë°± ì •ë¦¬
    text = re.sub(r'\n{3,}', '\n\n', text).strip()
    return text


# âœ… ë¡œê·¸ë¥¼ "ì´ë¦„ - ë‚´ìš©"ìœ¼ë¡œ ì •ê·œí™”
def normalize_dialog(text: str) -> str:
    """
    ë‹¤ìŒê³¼ ê°™ì€ í”í•œ íŒ¨í„´ë“¤ì„ 'ì´ë¦„ - ë‚´ìš©'ìœ¼ë¡œ í†µì¼:
    1) [ì´ë¦„] [ì‹œê°„] ë‚´ìš©
    2) [ì´ë¦„] ë‚´ìš©
    3) ì´ë¦„: ë‚´ìš©
    4) ì´ë¦„ - ë‚´ìš©
    ê·¸ ì™¸ ë§¤ì¹˜ë˜ì§€ ì•Šìœ¼ë©´ ê³µë°± ì •ë¦¬ í›„ ì›ë¬¸ ìœ ì§€
    """
    patterns = [
        re.compile(r'^\s*\[(?P<name>[^\]]+)\]\s*\[(?P<time>[^\]]*)\]\s*(?P<content>.+)\s*$'),
        re.compile(r'^\s*\[(?P<name>[^\]]+)\]\s*(?P<content>.+)\s*$'),
        re.compile(r'^\s*(?P<name>[^:\-\[\]]+)\s*[:\-]\s*(?P<content>.+)\s*$'),
    ]
    out = []
    for raw in text.strip().splitlines():
        line = raw.strip()
        if not line:
            continue
        normalized = None
        for p in patterns:
            m = p.match(line)
            if m:
                name = re.sub(r'\s+', ' ', m.group('name').strip())
                content = re.sub(r'\s+', ' ', m.group('content').strip())
                normalized = f"{name} - {content}"
                break
        out.append(normalized if normalized else re.sub(r'\s+', ' ', line))
    return "\n".join(out)

user_log = st.chat_input("ì—¬ê¸°ì— 'ëŒ€í™” ë¡œê·¸'ë¥¼ ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ê³  Enter")
if user_log:
    # 1) ì •ê·œí™”í•´ì„œ í™”ë©´ì— ê¹”ë”íˆ ë³´ì—¬ì£¼ê¸°
    norm_log = normalize_dialog(user_log)
    with st.chat_message("user"):
        st.markdown("**ì •ê·œí™”ëœ ëŒ€í™”**")
        st.code(norm_log)

    # 2) ëª¨ë¸ì—ë„ ì •ê·œí™”ëœ ë¡œê·¸ë¥¼ ì „ë‹¬
    user_content = f"""
ì´ ëŒ€í™”ì—ì„œ ìƒëŒ€ë°©ê³¼ ëŒ€í™”ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ê¸° ìœ„í•´, ë‹¤ìŒì— ì–´ë–¤ ë§ì„ í•˜ë©´ ì¢‹ì„ì§€ í•œêµ­ì–´ë¡œ ì¶”ì²œí•´ì¤˜.

[ëŒ€í™” ë¡œê·¸ ì‹œì‘]
{norm_log}
[ëŒ€í™” ë¡œê·¸ ë]

ì¡°ê±´:
- ë°˜ë§, ê³µê°, ê°€ë²¼ìš´ ìœ ë¨¸ í—ˆìš©
- {N}ê°œ ì œì•ˆ, ê° 1ë¬¸ì¥/30ì ë‚´ì™¸
"""

    with st.chat_message("assistant"):
        if not ensure_model_exists(MODEL.strip()):
            st.stop()

        try:
            res = ollama.chat(
                model=MODEL.strip(),
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_content},
                ],
                options={"temperature": float(TEMP), "num_ctx": 4096},
            )
            # â–¼â–¼â–¼ ì¶”ê°€: thinking/íˆ´ì½œ ë“± ì œê±° â–¼â–¼â–¼
            raw = res["message"]["content"].replace("\\n", "\n").strip()
            text = clean_model_output(raw)

            # ë¼ì¸ ì •ë¦¬
            lines = [
                ln.strip(" -â€¢0123456789.").strip()
                for ln in text.splitlines() if ln.strip()
            ]
            lines = lines[:N] if len(lines) >= N else lines

            if not lines:
                st.markdown("ìƒì„±ëœ ì œì•ˆì´ ì—†ë„¤. ë¡œê·¸ë¥¼ ì¡°ê¸ˆ ë” ë¶™ì—¬ì¤˜! ğŸ˜…")
            else:
                for i, ln in enumerate(lines, 1):
                    st.markdown(f"{i}. {ln}")

            st.caption(f"ëª¨ë¸: **{res.get('model', MODEL)}** | temp={TEMP}")
            st.session_state.turns.append((norm_log, lines))

        except Exception as e:
            st.error(f"ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨: {e}\n- `ollama serve`ê°€ ì‹¤í–‰ ì¤‘ì¸ì§€ì™€ ëª¨ë¸ëª…ì„ í™•ì¸í•´ì¤˜.")

# (ì„ íƒ) ì´ì „ ì¶”ì²œ ë³´ê¸°
if st.session_state.turns:
    with st.expander("ì´ì „ ì¶”ì²œ ë³´ê¸°"):
        for i, (logs, suggs) in enumerate(reversed(st.session_state.turns), 1):
            st.markdown(f"**#{i} ì…ë ¥ ë¡œê·¸ (ì •ê·œí™”)**")
            st.code(logs)
            if suggs:
                for j, ln in enumerate(suggs, 1):
                    st.markdown(f"{j}. {ln}")

#streamlit run ST.py ìœ¼ë¡œ ì‹¤í–‰í•˜ë©´ ë¨